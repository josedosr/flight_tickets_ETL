{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb4dd31",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Grupo G - Comparador de precios de vuelos navideños: encuentra las mejores ofertas para tus vacaciones de navidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d386b1d",
   "metadata": {},
   "source": [
    "#### Autores: Daniel Muñoz, José Dos Reis y Pamela J. Colman Vega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3f330",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef5d246-7771-4948-a2c0-ba6ae10e3c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Librerías para arrays y data frames\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Librerías para datos de fechas, horas, tiempo\n",
    "import time\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "#Librerías para el Web Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import locale\n",
    "\n",
    "#Librerías para cargar API_KEYS y demás funciones del sistema operativo\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tqdm\n",
    "\n",
    "#Librerías para gestión de archivos o ficheros\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "#Librerías para hacer gráficas y plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417d2b2",
   "metadata": {},
   "source": [
    "## Extracción de los datos: web scraping de eDreams y Kayak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fbe596",
   "metadata": {},
   "source": [
    "#### Los datos son obtenidos mediante scraping web con selenium y BeautifulSoup de las páginas de eDreams y Kayak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15283e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Driver de Chrome\n",
    "chrome_driver = \"chromedriver.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c3dd10",
   "metadata": {},
   "source": [
    "### eDreams\n",
    "**`eDreams`** nos permite una busqueda abierta donde a partir de un origen y unas fechas de ida/vuelta, te ofrece 15 destinos sobre los que mediante scraping podemos obtener gran cantidad de vuelos y combinaciones.\n",
    "\n",
    "*__Link__: https://www.edreams.es*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd834e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Funciones\n",
    "\n",
    "#Funcion principal del scrapeo a edreams. Gestiona todas las acciones necesarias para scrapear (selenium, diferentes urls, soap, preparar y devolver datos)\n",
    "def scrapping_edreams( origen, inicio, fin):\n",
    "    print(f\"Procesando {origen} - {inicio} to {fin}\")\n",
    "    url = f\"https://www.edreams.es\"\n",
    "    \n",
    "    #Llamada a la funcion que se encarga de hacer las acciones necesarias mediante selenium para lanzar la busquesda inicial por origen + fechas\n",
    "    soup = obtener_posibles_destinos(url=url, origen=origen, inicio=inicio, fin=fin)\n",
    "\n",
    "    #Generar las URLs de destinos+fechas basado en el contenido de la etiqueta article y la plantilla de url\n",
    "    #\"{url}/travel/#results/type=R;dep={inicio};from={origen};to={destino};ret={fin};collectionmethod=false\"\n",
    "    destinos = soup.find_all(\"article\", class_ = \"od-inspirational-grid-col\")\n",
    "    #obtenemos los codigos IATA sobre los que luego buscaremos al intruducirlos como parametros en la URL\n",
    "    lista_destinos = [destino.find(\"figure\")[\"data-iata\"] for destino in destinos]\n",
    "    \n",
    "    urls_destinos = {}\n",
    "    for destino in lista_destinos:\n",
    "        #url_template = f\"{url}/travel/#results/type=R;dep={inicio};from={origen};to={???};ret={fin};collectionmethod=false\"\n",
    "        urls_destinos[destino] = f\"{url}/travel/#results/type=R;dep={inicio};from={origen};to={destino};ret={fin};collectionmethod=false\"\n",
    "\n",
    "    #scrap data\n",
    "    datos_scrapeados = []\n",
    "    for destino,destino_url in tqdm.tqdm(urls_destinos.items(), total=len(urls_destinos)):\n",
    "        #datos fijos que sabemos por la propia busqueda: url, origen, destino, inicio, fin\n",
    "        fixed_data = [destino_url, origen, destino, inicio, fin]\n",
    "\n",
    "        #datos obtenidos del scrapeo de la url con los vuelos a ese destino\n",
    "        data_destino = datos_destino(url=destino_url)\n",
    "\n",
    "        #list comprehension para nutrir cada elemento con los valores fijos\n",
    "        full_data_destino = [fixed_data + rd for rd in data_destino]\n",
    "    \n",
    "        datos_scrapeados.extend(full_data_destino)\n",
    "\n",
    "    return datos_scrapeados\n",
    "\n",
    "#Funcion que realiza con selenium todas las acciones dinamicas para poder obtener todos los posibles destinos en base a un origen y unas fechas\n",
    "def obtener_posibles_destinos(url, origen, inicio, fin):\n",
    "\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    sleep(1)\n",
    "    browser.maximize_window()\n",
    "    sleep(1)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        #aceptar cookies\n",
    "        browser.find_element(By.ID, \"didomi-notice-agree-button\").click()\n",
    "        sleep(1)\n",
    "\n",
    "        #Escribir en el inputo de origen el valor recibido\n",
    "        browser.find_element(By.XPATH, '//input[@test-id=\"input-airport\"]').send_keys(origen)\n",
    "        sleep(1)\n",
    "\n",
    "        #Click en el origen que se muestra como resultado del paso anterior\n",
    "        browser.find_element(By.XPATH, '//div[@test-id=\"airport-departure\"]').find_element(By.XPATH, f\".//ul/li/div/span[contains(text(), \\\"{origen}\\\")]\").click()\n",
    "        sleep(1)\n",
    "\n",
    "        #Click en la primera opcion de destino que se muestra al hacer el paso anterior, que es cualquier destino\n",
    "        browser.find_element(By.XPATH, '//div[@test-id=\"airport-destination\"]').find_element(By.XPATH, './/div/div/ul/li/div[contains(@class, \"odf-dropdown-col\") and contains(@class, \"lg\") and contains(@class, \"odf-text-nowrap\")]').click()\n",
    "        sleep(1)\n",
    "\n",
    "        #Logica para abrir el calendario y elegir las fechas que hemos recibido, fecha de inicio\n",
    "        div_calendario_salida = browser.find_element(By.XPATH, '//div[@data-testid=\"departure-date-picker\"]')\n",
    "        procesar_calendario(fecha=inicio, element=div_calendario_salida)\n",
    "        sleep(1)\n",
    "\n",
    "        #Logica para abrir el calendario y elegir las fechas que hemos recibido, fecha de fin\n",
    "        div_calendario_vuelta = browser.find_element(By.XPATH, '//div[@data-testid=\"return-date-picker\"]')\n",
    "        procesar_calendario(fecha=fin, element=div_calendario_vuelta)\n",
    "        sleep(1)\n",
    "\n",
    "        #Click en el boton Continuar para confirmar las fechas (y todo lo previo)\n",
    "        div_calendario_vuelta.find_element(By.XPATH, \".//div/button[contains(text(), \\\"Continuar\\\")]\").click()\n",
    "\n",
    "        #Lanzar la busqueda de destinos\n",
    "        boton_buscar = browser.find_element(By.XPATH, '//button[@test-id=\"search-flights-btn\"]')\n",
    "        boton_buscar.click()\n",
    "        sleep(10)\n",
    "\n",
    "        #Una vez ha cargado los resultados, lo montamos en BS y lo devolvemos\n",
    "        soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "        browser.quit()\n",
    "\n",
    "        if soup is None:\n",
    "            raise Exception\n",
    "\n",
    "        return soup\n",
    "    \n",
    "    except Exception as exception:\n",
    "        print(f\"Excepcion buscando destinos... {exception}\")\n",
    "        return None\n",
    "\n",
    "#Funcion para parsear la fecha recibida a un formato especial que hay en la pagina\n",
    "def custom_ano_mes_format( fecha = datetime.now()):\n",
    "\n",
    "    locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "    #Obtener el nombre del mes en formato completo (por ejemplo, \"noviembre\")\n",
    "    parsed_month = fecha.strftime('%B').capitalize()\n",
    "\n",
    "    #Obtener los dos últimos dígitos del año (por ejemplo, \"23\" en lugar de \"2023\")\n",
    "    parsed_year = fecha.strftime('%y')\n",
    "\n",
    "    #Formatear la fecha en el formato deseado \"Mes 'YY\"\n",
    "    formatted_fecha = f\"{parsed_month} '{parsed_year}\"\n",
    "    \n",
    "    return formatted_fecha\n",
    "\n",
    "#Funcion para mostrar el mes deseado, via selenium\n",
    "def mostrar_mes(ano_mes_str, html_element):\n",
    "    while True:\n",
    "        #Obtener los calendarios de los meses que actualmente vemos en la pagina\n",
    "        meses_visibles = [e.text for e in html_element.find_elements(By.CSS_SELECTOR, \"div.odf-calendar-title\")]\n",
    "\n",
    "        #Comprobamos si tenemos visible el mes que queremos\n",
    "        if ano_mes_str in meses_visibles:\n",
    "            #Si el mes que buscamos esta en pantalla, salimos\n",
    "            break\n",
    "        else:\n",
    "            #Si no esta visible el mes, hacemos click en el boton de siguiente mes y volvemos al inicio del while\n",
    "            html_element.find_element(By.XPATH, './/div/div/div/button/span[contains(@class, \"odf-icon-arrow-right\")]').click()\n",
    "\n",
    "    return\n",
    "\n",
    "#Funcion para procesar las acciones necesarias con selenium para mostrar el calendario\n",
    "def procesar_calendario(fecha, element):\n",
    "    #A partir de la fecha recibida, transformamos a formato \"Mes 'YY\" que es lo que la web muestra y por lo tanto hay que buscar\n",
    "    fecha_datetime = datetime.strptime(fecha, \"%Y-%m-%d\")\n",
    "    fecha_ano_mes = custom_ano_mes_format(fecha_datetime)\n",
    "\n",
    "    #La pagina nos muestra 2 meses, el actual y el siguiente, pero debemos buscar realmente el que corresponda a la fecha recibida\n",
    "    mostrar_mes(ano_mes_str=fecha_ano_mes, html_element=element)\n",
    "\n",
    "    #Una vez tenemos visible el mes que queremos, buscamos el mes\n",
    "    calendario_fecha = element.find_element(By.XPATH, f\".//div[contains(@class, \\\"odf-calendar-title\\\") and contains(text(), \\\"{fecha_ano_mes}\\\")]/following-sibling::div\")\n",
    "\n",
    "    #Buscamos el dia dentro de ese mes, y le hacemos click\n",
    "    dia_fecha = calendario_fecha.find_element(By.XPATH, f\".//div[contains(@class, \\\"odf-calendar-day\\\") and contains(text(), \\\"{fecha_datetime.day}\\\")]\")\n",
    "\n",
    "    #Le hacemos click\n",
    "    dia_fecha.click()\n",
    "\n",
    "#Funcion para detectar y quitar una alerta/boton molesto\n",
    "def check_boton_molesto(browser):\n",
    "    #check stupid alert\n",
    "    try:\n",
    "        stupid_alert = browser.find_element(By.ID, \"sessionAboutToExpireAlert\")\n",
    "\n",
    "        if stupid_alert:\n",
    "            stupid_button = stupid_alert.find_element(By.CCS_SELECTOR, \"button\")\n",
    "            if stupid_button:\n",
    "                stupid_button.click()\n",
    "                sleep(1)\n",
    "                return True\n",
    "    except Exception:\n",
    "        # print(\"Error detectando el boton estupido...\")\n",
    "        return False\n",
    "\n",
    "    return False\n",
    "\n",
    "#Funcion para scrapear con selenuim y BS el detalle de los vuelos segun la url recibida que contiene ya el conjunto de datos de origen, destino, inicio y fin\n",
    "def datos_destino(url):\n",
    "    print(f\"Processing {url}\")\n",
    "    lista_datos_destino = []\n",
    "    \n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    sleep(1)\n",
    "    browser.maximize_window()\n",
    "    sleep(15)\n",
    "\n",
    "    #Aceptar cookies\n",
    "    browser.find_element(By.ID, \"didomi-notice-agree-button\").click()\n",
    "    sleep(1)\n",
    "\n",
    "    #Bucle para hacer scroll y clieck en mostrar mas resultados, hasta que no se pueda hacer mas scroll\n",
    "    counter = 0\n",
    "    scroll = 10000\n",
    "    while True:\n",
    "        #Scroll\n",
    "        browser.execute_script(f\"window.scrollBy(0, {scroll});\")\n",
    "        sleep(6)\n",
    "        #Checkeamos si existe un boton molesto, y lo quitamos\n",
    "        check_boton_molesto(browser=browser)\n",
    "\n",
    "        #Buscamos los botones\n",
    "        botones = browser.find_element(By.ID, \"results_list_container\").find_elements(By.XPATH, \".//button\")\n",
    "\n",
    "        #Si hay botones y el ultimo boton contiene \"Mostrar \", le damos click\n",
    "        if len(botones) and botones[-1] and \"Mostrar \" in botones[-1].text:\n",
    "            # print(\"Click en \" + botones[-1].text)\n",
    "            try:\n",
    "                botones[-1].click()\n",
    "            except Exception:\n",
    "                #En caso de error, checkeamos si existe el boton molesto, y lo quitamos\n",
    "                if check_boton_molesto(browser=browser):\n",
    "                    print(f\"Boton estupido detectado y clickado :)\")\n",
    "                    continue\n",
    "                else:\n",
    "                    #Si hay error desconocido, simplemente dejamos de hacer scroll y pasamos a extraer datos\n",
    "                    break\n",
    "\n",
    "            counter += 1\n",
    "            #Cada bucle aumentamos el scroll\n",
    "            scroll += 500\n",
    "\n",
    "        elif not check_boton_molesto(browser=browser):\n",
    "            #Si no tengo botones ni boton molesto, dejo de hacer scroll\n",
    "            break\n",
    "\n",
    "    sleep(4)\n",
    "    print(f\"Scroll hecho {counter} veces\")\n",
    "\n",
    "\n",
    "    #Montamos el BS con el contenido\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    browser.quit()\n",
    "\n",
    "    #Contenedor con todos los divs de vuelos\n",
    "    results_container = soup.find(id = \"results_list_container\")\n",
    "    elements = results_container.find_all(attrs={\"data-testid\" : \"itinerary\"})\n",
    "\n",
    "    for element in elements:\n",
    "        duraciones = []\n",
    "        escalas = []\n",
    "        datos_horas = []\n",
    "        equipajes = []\n",
    "\n",
    "        try:\n",
    "            #Aeropuertos, es una lista con los 2 de la ida y los 2 de la vuelta\n",
    "            aeropuertos = element.find_all('div', {'type': 'small'})\n",
    "            aeropuertos_data = [aeropuertos[0].text.strip(),aeropuertos[2].text.strip(),aeropuertos[4].text.strip(),aeropuertos[6].text.strip()]\n",
    "            \n",
    "            #Aerolineas, las dejamos en una lista de valores unicos\n",
    "            aerolineas_elem = element.find_all('img')\n",
    "            aerolineas = list({a.attrs[\"alt\"] for a in aerolineas_elem if 'alt' in a.attrs})\n",
    "            \n",
    "            #Precios. El bueno es el unit_price, pero tambien hay otros precios con descuento que pueden servir\n",
    "            price_spans = element.find_all('span', class_ = \"money-integer\")\n",
    "            prices = [p.text for p in price_spans]\n",
    "            unit_price = element.select(\"a > span > span.money-integer\")[0].text\n",
    "\n",
    "            #Variable para tener todos los divs del vuelo\n",
    "            divs_vuelo = element.find_all('div')\n",
    "\n",
    "            #Bucle para iterar por todos los divs y sacar los diferentes datos\n",
    "            for div_item in divs_vuelo:\n",
    "                #Logica para sacar las horas de despegue y llegada\n",
    "                if len(div_item.attrs) == 1 and \"class\" in div_item.attrs:\n",
    "                    #Al ser clases css dinamicas, hay que recorrerlas y buscar la que acabe en BaseText-Body que es estatico. \n",
    "                    for attr_class in div_item.attrs[\"class\"]:\n",
    "                        #Regex para buscar en el contenido del div que tenga un formato de XX:XX\n",
    "                        if attr_class.endswith(\"BaseText-Body\") and re.match(r'^\\d{2}:\\d{2}$', div_item.text.strip()):\n",
    "                            datos_horas.append(div_item.text)\n",
    "                #Logica para sacar datos de escalas, a partir de un atributo orientation que tiene ese elemento\n",
    "                elif len(div_item.attrs) > 1 and \"orientation\" in div_item.attrs:\n",
    "                    #Es imposible detectar directamente el elemento, por eso buscamos el anterior que si podemos encontrar, y vamos al siguiente sibling\n",
    "                    next_sibling = div_item.findNextSibling()\n",
    "                    if next_sibling:\n",
    "                        #El span contiene las duraciones y las escalas\n",
    "                        span_items = next_sibling.find_all(\"span\")\n",
    "                        duraciones.append(span_items[0].text)\n",
    "                        escalas.append( span_items[1].text if len(span_items) > 1 else \"0\" )\n",
    "\n",
    "            #Bucle para iterar por todos los elementos path y sacar datos\n",
    "            child_paths = element.find_all('path')\n",
    "            for path_item in child_paths:\n",
    "                #clip-rule es algo fijo que siempre podremos encontrar\n",
    "                if len(path_item.attrs) > 1 and \"clip-rule\" in path_item.attrs:\n",
    "                    #ojo sensibles: buscamos tres veces el parent\n",
    "                    tri_parent = path_item.parent.parent.parent\n",
    "                    if tri_parent:\n",
    "                        #buscamos el siguiente elemento\n",
    "                        equipaje_div = tri_parent.findNextSibling() \n",
    "                        if equipaje_div:\n",
    "                            #agregamos la info de maletas\n",
    "                            equipajes.append(equipaje_div.text)\n",
    "\n",
    "        except Exception as exception:\n",
    "            print(f\"Ignorando vuelo por problemas al scrapear...{exception}\")\n",
    "            continue\n",
    "\n",
    "        lista_datos_destino.append( [aeropuertos_data,aerolineas,datos_horas,duraciones,escalas,equipajes,unit_price,prices] )\n",
    "\n",
    "    return lista_datos_destino\n",
    "\n",
    "\n",
    "AIRTABLE_BASE_URL = \"https://api.airtable.com/v0\"\n",
    "BASE_ID = \"appeoVItHkVNqxCPe\" # Base: Tabla API\n",
    "TABLE_ID  = \"tblc9PqQwMxECrPf0\" # Tabla: Data Base\n",
    "\n",
    "#Funcion para subir a airtables el df\n",
    "def subir_datos_airtable(df):\n",
    "    API_KEY = os.getenv(\"AIRTABLE_API_KEY_SHARED\") #API KEY de AirTable cargada desde el ordenador mediante un fichero .env\n",
    "\n",
    "    # Headers - Credenciales para hacer solicitudes mediante API en AirTable\n",
    "    headers = {\"Authorization\" : f\"Bearer {API_KEY}\",\n",
    "            \"Content-Type\"  : \"application/json\"}\n",
    "\n",
    "    # Formateos para evitar errores\n",
    "    df1 = df.replace({\"\" :  None})\n",
    "    df1 = df1.replace({np.nan :  None})\n",
    "\n",
    "    datos_df = []\n",
    "\n",
    "    for idx, row in df1.iterrows():\n",
    "        data = {'fields': row.to_dict()}\n",
    "        datos_df.append(data)\n",
    "\n",
    "    # endpoint\n",
    "    endpoint = f\"{AIRTABLE_BASE_URL}/{BASE_ID}/{TABLE_ID}\"\n",
    "\n",
    "    counter = 0\n",
    "    while counter < len(datos_df):\n",
    "        datos_subir = datos_df[counter:counter+10]\n",
    "        datos_subir = {'records': datos_subir, 'typecast': True }\n",
    "        \n",
    "        response = requests.post(url = endpoint, json = datos_subir, headers = headers)\n",
    "\n",
    "        (f\"response: {response.status_code}\")\n",
    "        # print(f\"endpoint: {response.url}\")\n",
    "        # print(\"-\"*120)\n",
    "        counter += 10\n",
    "        sleep(1)\n",
    "\n",
    "    print(f\"Subidos {len(datos_df)} registros a airtables\")\n",
    "    \n",
    "#Funcion para crear el df con los datos scrapeados de edreams\n",
    "def crear_df(data):\n",
    "    columnas_df = ['url', 'origen', 'destino', 'fecha_inicio', 'fecha_fin', 'pasajeros', 'inicio_ida', 'fin_ida', 'inicio_vuelta', 'fin_vuelta', 'escala_ida', 'escala_vuelta', 'duracion_ida', 'duracion_vuelta', 'aerolineas', 'equipaje_mano', 'equipaje_bodega', 'precio', 'clase']\n",
    "    df = pd.DataFrame(data, columns = columnas_df)\n",
    "\n",
    "    #Ajusta las columnas de escalas para que sea solo el numero. De origen viene directo o X escalas\n",
    "    df['escala_ida'] = df.apply(lambda row: int(row[\"escala_ida\"][:1] if row[\"escala_ida\"] != \"directo\" else 0), axis=1)\n",
    "    df['escala_vuelta'] = df.apply(lambda row: int(row[\"escala_vuelta\"][:1] if row[\"escala_vuelta\"] != \"directo\" else 0), axis=1)\n",
    "\n",
    "    #Ajusta las columnas de duracion para que el formato sea 1h 35m en vez de 1 h 35 min\n",
    "    df['duracion_ida'] = df.apply(lambda row: row['duracion_ida'].replace(\" h\",\"h\").replace(\" min\",\"m\"), axis=1)\n",
    "    df['duracion_vuelta'] = df.apply(lambda row: row['duracion_vuelta'].replace(\" h\",\"h\").replace(\" min\",\"m\"), axis=1)\n",
    "\n",
    "    #guardar en pkl el df con un timestamp\n",
    "    now = datetime.now()\n",
    "    now_timestamp = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    file_name = f\"edreams_data_{now_timestamp}\"\n",
    "    df.to_pickle(f\"{file_name}.pkl\")\n",
    "    print(f\"Creado {file_name}.pkl\")## Ejecución del proceso\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911ddcb",
   "metadata": {},
   "source": [
    "##### Ejecución del proceso de scrapeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d71be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Lista/Diccionario con el conjunto de fechas a Scrapear\n",
    "fechas = [\n",
    "    {\n",
    "        \"inicio\" : \"2023-12-06\",\n",
    "        \"fin\" : \"2023-12-10\"\n",
    "    },\n",
    "    {\n",
    "        \"inicio\" : \"2023-12-22\",\n",
    "        \"fin\" : \"2023-12-26\"\n",
    "    },\n",
    "    {\n",
    "        \"inicio\" : \"2023-12-29\",\n",
    "        \"fin\" : \"2024-01-02\"\n",
    "    },\n",
    "    {\n",
    "        \"inicio\" : \"2024-01-05\",\n",
    "        \"fin\" : \"2024-01-09\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#Lista de origenes a scrapear\n",
    "origenes = [\"MAD\",\"PMI\",\"LCG\"]\n",
    "\n",
    "#Bucle para recorrer cada uno de los origenes\n",
    "for origen in origenes:\n",
    "    #Bucle para recorrer cada una de las fechas\n",
    "    for date in fechas:\n",
    "        data = []\n",
    "        #Llamada a la funcion que, en base al origen + fechas, lanza todo el scrapeo necesario y nos devuelve una lista de valores\n",
    "        lista_datos_obtenidos = scrapping_edreams( origen = origen, inicio = date['inicio'], fin = date['fin'])\n",
    "\n",
    "        #Bucle para recopilar los datos obtenidos del scrapeo, setear algunos datos fijos, parsear y tener el conjunto de datos finales para generar el df\n",
    "        for datos_obtenidos in lista_datos_obtenidos:\n",
    "            url = datos_obtenidos[0]\n",
    "            origen = datos_obtenidos[1]\n",
    "            destino = datos_obtenidos[2]\n",
    "            fecha_inicio = datos_obtenidos[3]\n",
    "            fecha_fin = datos_obtenidos[4]\n",
    "            pasajeros = 1 #valor fijo\n",
    "            inicio_ida = datos_obtenidos[7][0]\n",
    "            fin_ida = datos_obtenidos[7][1]\n",
    "            inicio_vuelta = datos_obtenidos[7][2]\n",
    "            fin_vuelta = datos_obtenidos[7][3]\n",
    "            escala_ida = datos_obtenidos[9][0]\n",
    "            escala_vuelta = datos_obtenidos[9][1]\n",
    "            duracion_ida = datos_obtenidos[8][0]\n",
    "            duracion_vuelta = datos_obtenidos[8][1]\n",
    "            aerolineas = datos_obtenidos[6]\n",
    "            equipaje_mano_value = datos_obtenidos[10][0] if len(datos_obtenidos[10])>1 else \"\" #En edreams solo podemos detectar equipaje de mano, buscamos ese valor y sino 0\n",
    "            equipaje_mano = 1 if equipaje_mano_value == \"Equipaje de mano\" else 0\n",
    "            equipaje_bodega = 0 #no existe este valor en edreams\n",
    "            precio = datos_obtenidos[11]\n",
    "            clase = None #no existe este valor en edreams\n",
    "\n",
    "            data.append([url,origen, destino, fecha_inicio, fecha_fin, pasajeros, inicio_ida, fin_ida, inicio_vuelta, fin_vuelta, escala_ida, escala_vuelta, duracion_ida, duracion_vuelta, aerolineas, equipaje_mano, equipaje_bodega, precio, clase])\n",
    "        \n",
    "        if len(data)>0:\n",
    "            #Creamos el df\n",
    "            data_df = crear_df(data=data)\n",
    "            #Subimos el df a airtables\n",
    "            subir_datos_airtable(df=data_df)\n",
    "    print(\"===================== FIN DEL PROCESO =====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e8ee0",
   "metadata": {},
   "source": [
    "### Kayak\n",
    "\n",
    "**`kayak`** nos permite una busqueda abierta donde a partir de un origen y unas fechas de ida/vuelta, te ofrece 15 destinos sobre los que mediante scraping podemos obtener gran cantidad de vuelos y combinaciones.\n",
    "\n",
    "*__Link__: https://www.kayak.es*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d8a2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Diccionario key:value de Ciudades con su código IATA\n",
    "\n",
    "Los códigos IATA consisten en un código de tres letras que suele tener relación con la ciudad o región \n",
    "a la que sirve el aeropuerto, o bien el nombre del aeródromo existente antes de la creación del aeropuerto,\n",
    "pero que no tiene por qué contener información geográfica del mismo.\"\"\"\n",
    "\n",
    "aeropuertos_espana = {\n",
    "    \"Madrid\": \"MAD\",\n",
    "    \"Barcelona\": \"BCN\",\n",
    "    \"Valencia\": \"VLC\",\n",
    "    \"Sevilla\": \"SVQ\",\n",
    "    \"Malaga\": \"AGP\",\n",
    "    \"Bilbao\": \"BIO\",\n",
    "    \"Mallorca\": \"PMI\",\n",
    "    \"GranCanaria\": \"LPA\",\n",
    "    \"TenerifeNorte\": \"TFN\",\n",
    "    \"TenerifeSur\": \"TFS\",\n",
    "    \"Alicante\": \"ALC\"\n",
    "}\n",
    "\n",
    "#Diccionario con claves de ciudades, valor códigos IATA de los aeropuertos de respectivas ciudades\n",
    "with open(\"iata.pkl\", \"br\") as file:\n",
    "    ciudades_iata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e5db19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origen = aeropuertos_espana['Madrid']\n",
    "\n",
    "destinos = []\n",
    "\n",
    "#Se visita la pag web donde estarán todos los destino posibles de ese momento\n",
    "\n",
    "url_visitar = f'https://www.kayak.es/explore/{origen}-anywhere'\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "browser.get(url=url_visitar)\n",
    "\n",
    "browser.maximize_window()\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "browser.find_element(By.CLASS_NAME, 'RxNS-button-container').click() #Esta línea de código acepta términos y condiciones de la web/cookies.\n",
    "\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700391c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cargar_destinos():#Esta función carga las páginas o demás resultados que arroja la web al buscar una ruta de un origen a un destino cualquiera, suele arrojar hasta 100-120 destinos\n",
    "\n",
    "    #Como acceder al botón mediante algún patrón en el html del sitio es bastante complejo se opta por hacerlo mediante XPATH, aún así en el diversos tests se ha encontrado que el botón tiene otras posibles ubicaciones\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            boton_cargar_destinos = browser.find_element(By.XPATH, '/html/body/div[1]/div[1]/main/div[2]/div[2]/div[2]/div/div[2]/div/div/div/div[6]/button')\n",
    "            boton_cargar_destinos.click()\n",
    "            sleep(2.5)\n",
    "            print('Try - 1')\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                boton_cargar_destinos = browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/main/div[2]/div[2]/div[2]/div/div[2]/div/div/div/div[6]/button')\n",
    "                boton_cargar_destinos.click()\n",
    "                sleep(2.5)\n",
    "                print('Try - 2')\n",
    "\n",
    "            except:\n",
    "                print('No hay más destinos que cargar')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c08c18af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try - 2\n",
      "Try - 2\n",
      "Try - 2\n",
      "Try - 2\n",
      "Try - 2\n",
      "Try - 2\n",
      "Try - 2\n",
      "No hay más destinos que cargar\n"
     ]
    }
   ],
   "source": [
    "cargar_destinos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72445cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Una vez conseguidas todas las ciudades que tiene la web para mostrarnos, se hace un BeautifulSoup para extraer los nombres de las ciudades\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser') #Se crea el soup para tener el html de la web y poder explorar en ella\n",
    "\n",
    "ciudades = soup.find_all('div', class_ = 'City__Name') #Se consiguen todos los elementos que tienen el nombre de la ciudad\n",
    "\n",
    "ciudades = [ciudad.text for ciudad in ciudades] #Se guarda en una lista el string que contiene los elementos encontrados en la linea anterior\n",
    "\n",
    "print(f'Se han encontrado {len(ciudades)} posibles destinos desde {origen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c54bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def buscar_codigo_iata(ciudad): #Con esta función se busca el nombre de la ciudad que falta en el diccionario ciudades_iata, consultando la web oficial de IATA (tienen una API que lo hace pero sigue en desarrollo)\n",
    "    \n",
    "    with open(\"iata.pkl\", \"br\") as file:\n",
    "        ciudades_iata = pickle.load(file)\n",
    "    \n",
    "    try:\n",
    "        url_query = f'https://www.iata.org/en/publications/directories/code-search/?airport.search={ciudad}'\n",
    "\n",
    "        browser.get(url=url_query)\n",
    "\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "        codigo_iata = soup.find('table', class_ = 'datatable').find('td', attrs={'data-heading': '3-letter location code'}).text\n",
    "\n",
    "        ciudades_iata[ciudad] = codigo_iata\n",
    "        \n",
    "        sleep(1)\n",
    "        \n",
    "    finally:\n",
    "        \n",
    "        with open(\"iata.pkl\", \"bw\") as file:\n",
    "            pickle.dump(ciudades_iata, file)\n",
    "        \n",
    "        return ciudades_iata[ciudad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b519c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"iata.pkl\", \"br\") as file:\n",
    "    ciudades_iata = pickle.load(file)\n",
    "    \n",
    "#Esta list comprehension ayuda a saber qué resultados de la búsqueda anterior no están en el diccionario cargado del archivo pickle donde están los códigos IATA\n",
    "\n",
    "ciudades_faltantes = [ciudad for ciudad in ciudades if ciudad not in ciudades_iata]\n",
    "\n",
    "for ciudad in ciudades_faltantes:\n",
    "\n",
    "    try:\n",
    "        buscar_codigo_iata(ciudad) #Con esta función se busca el nombre de la ciudad que falta en el diccionario consultando la web oficial de IATA\n",
    "    \n",
    "    except:\n",
    "        print(f'No se ha encontrado {ciudad} en la búsqueda y se ha eliminado de la lista de ciudades destino') #Si no encuentra el código IATA de la fuente oficial se descarta el posible destino\n",
    "        ciudades.remove(ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa0970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cargar_resultados(): #Esta función se emplea para cargar en la página de vuelos de origen-destino en el rango de fechas deseado.\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    #Cada página tiene un máximo de 15 resultados, al cargar todas las páginas hasta 10 se podrán sacar hasta 150 vuelos por ruta (puede haber menos)\n",
    "    while counter<10: #Si se desea sacar todos los vuelos de una ruta este código se puede cambiar a un while True\n",
    "        \n",
    "        try:\n",
    "            boton_cargar_resultados = browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/main/div/div[2]/div[2]/div[1]/div[2]/div[1]/div[3]/div[1]/div/div/div')\n",
    "            boton_cargar_resultados.click()\n",
    "            sleep(3)\n",
    "            counter += 1\n",
    "            #print(f'Cargando más resultados {counter}')\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            print(f'Se cargaron {counter} páginas adicionales')\n",
    "            #print('No hay más destinos que cargar')\n",
    "            \n",
    "            break\n",
    "        \n",
    "    print(f'Carga completa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a6740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extraer_vuelos(destino, fecha_inicio, fecha_fin, pasajeros = 1): #El parámetro pasajeros es opcional y definido a 1, si se quisiera cambiar el valor mediante un input o usando otra variable con un valor asignado\n",
    "    \n",
    "    counter = 0\n",
    "    for idx, vuelo in enumerate(vuelos):\n",
    "        try:\n",
    "            if counter % 50 == 0:\n",
    "                print(f'Estraidos datos de {counter} vuelos')\n",
    "            \n",
    "            #Datos del viaje\n",
    "            \n",
    "            #Horarios\n",
    "            horario = vuelo.find('div', class_ = 'nrc6-inner').find_all('div', class_ = 'VY2U')\n",
    "            horario = [viaje.find('div').text for viaje in horario]\n",
    "            inicio_ida, fin_ida = horario[0].split(' – ')\n",
    "            inicio_vuelta, fin_vuelta = horario[1].split(' – ')\n",
    "\n",
    "            #Escalas\n",
    "            escalas = vuelo.find('div', class_ = 'nrc6-inner').find_all('div', class_ = 'JWEO')\n",
    "            escala_ida, escala_vuelta = [int(parada.text[0]) if parada.text != 'directo' else 0 for parada in escalas]\n",
    "\n",
    "            #Duración vuelos\n",
    "            duraciones = vuelo.find('div', class_ = 'nrc6-inner').find_all('div', class_ = 'JWEO')\n",
    "            duracion_ida, duracion_vuelta = [duracion.find_next('div').find_next('div').find_next('div').text for duracion in duraciones]\n",
    "                \n",
    "            #Aerolinea\n",
    "            aerolineas = vuelo.find_all('img')\n",
    "            aerolineas = list({str(aerolinea).split('\"')[1] for aerolinea in aerolineas})   \n",
    "                \n",
    "            #Equipaje y Precio\n",
    "\n",
    "            equipaje_mano = vuelo.find('div', class_ = 'nrc6-price-section').text[0]\n",
    "            equipaje_bodega = vuelo.find('div', class_ = 'nrc6-price-section').text[1]\n",
    "            precio = float(vuelo.find('div', class_ = 'nrc6-price-section').text[2:].replace('\\xa0','').split('€')[0])\n",
    "            clase = vuelo.find('div', class_ = 'nrc6-price-section').text[2:].replace('\\xa0','').split('€')[1].replace('Seleccionar','')\n",
    "\n",
    "            data.append([url,origen, destino, fecha_inicio, fecha_fin, pasajeros, inicio_ida, fin_ida, inicio_vuelta, fin_vuelta, escala_ida, escala_vuelta, duracion_ida, duracion_vuelta, aerolineas, equipaje_mano, equipaje_bodega, precio, clase])\n",
    "\n",
    "            counter += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Problema vuelo {idx}. {e}\")\n",
    "            \n",
    "    print(f'Se han extraido de manera exitosa datos de {counter} vuelos de {len(vuelos)} | Accuracy {(counter/len(vuelos))*100}%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d7672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#De acuerdo con los datos que se han podido sacar del scrapeo se definen las columnas que se van a utilizar en el data frame\n",
    "columnas_df = ['url', 'origen', 'destino', 'fecha_inicio', 'fecha_fin', 'pasajeros', 'inicio_ida', 'fin_ida', 'inicio_vuelta', 'fin_vuelta', 'escala_ida', 'escala_vuelta', 'duracion_ida', 'duracion_vuelta', 'aerolineas', 'equipaje_mano', 'equipaje_bodega', 'precio', 'clase']\n",
    "\n",
    "#Se crea una lista vacía donde se va a guardar toda la información del scrapeo\n",
    "data = []\n",
    "\n",
    "#Esta variable es opcional ya que en la función anterior tiene asignada un 1 por defecto, se puede reemplazar con un input para pedir al usuario que ingrese el numero de pasajeros, pero en este caso se simulará con 1 pasajero\n",
    "pasajeros = 1\n",
    "\n",
    "#Aquí está la lista de fechas con un rango en una tupla (fecha_inicio, fecha_fin) de donde se van a extraer los datos mediante un bucle for\n",
    "fechas = [('2023-12-22','2023-12-26'), ('2023-12-29','2024-01-02')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd6565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"iata.pkl\", \"br\") as file: #Se abre el diccionario con los códigos IATA para que se pueda iterar sobre la URL de Kayak\n",
    "    ciudades_iata = pickle.load(file)\n",
    "    \n",
    "for idx, fecha in enumerate(fechas): #Se itera sobre la lista de rango de fechas que se quieren sacar los datos (cada elemento de esta lista son tuplas, que a su vez está conformada por un par de fechas en formato string)\n",
    "    \n",
    "    fecha_inicio = fecha[0]\n",
    "    fecha_fin = fecha[1]\n",
    "    fecha\n",
    "    \n",
    "    for idx, ciudad in tqdm.tqdm(enumerate(ciudades)): #Se itera sobre la lista de posibles destinos que se encontraron en la primera búsqueda de posibles destinos, y quitando los destinos no encontrados en la consulta a la web de IATA\n",
    "\n",
    "        destino = ciudades_iata[ciudad]\n",
    "\n",
    "        url = f'https://www.kayak.es/flights/{origen}-{destino}/{fecha_inicio}/{fecha_fin}/{pasajeros}adults?sort=price_a'\n",
    "\n",
    "        try:\n",
    "\n",
    "            browser.get(url)\n",
    "            sleep(30)\n",
    "            cargar_resultados()\n",
    "\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            vuelos = soup.find_all('div', class_ = 'nrc6')\n",
    "\n",
    "            extraer_vuelos(destino, fecha_inicio, fecha_fin, pasajeros) #Esta función tiene como parámetro opcional \"pasajeros\", si le pasamos esa variable antes con un input podemos sacar datos haciendo una búsqueda para 2 pasajeros\n",
    "\n",
    "            if idx % 2 == 0 or idx == (len(ciudades)): #Este código sirve para guardar el progreso de los scrappeado a medida que avanza el buble for\n",
    "                df = pd.DataFrame(data, columns = columnas_df)\n",
    "                df.to_pickle('kayak_webscraping_temp.pkl')\n",
    "                print(len(data))\n",
    "\n",
    "        except:\n",
    "\n",
    "            print(f'Ha fallado la extracción de datos de la ruta {origen}-{destino}/{fecha_inicio}/{fecha_fin}')\n",
    "        \n",
    "df = pd.DataFrame(data, columns = columnas_df)\n",
    "df.to_pickle('kayak_webscraping.pkl')\n",
    "df.to_csv('kayak_webscraping.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925de4a-25b5-44ac-a7d9-1acef9ab0b6e",
   "metadata": {},
   "source": [
    "### Carga de datos de Kayak a AirTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc812f3b-47e0-4eac-8cd9-71f08714ce21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(load_dotenv())\n",
    "\n",
    "API_KEY = os.getenv(\"AIRTABLE_API_KEY\") #API KEY de AirTable cargada desde el ordenador mediante un fichero .env\n",
    "\n",
    "BASE_ID = \"appeoVItHkVNqxCPe\" # Base: Tabla API\n",
    "\n",
    "TABLE_ID = \"tblc9PqQwMxECrPf0\" # Tabla: Data Base\n",
    "\n",
    "airtable_base_url = \"https://api.airtable.com/v0\"\n",
    "\n",
    "# Headers - Credenciales para hacer solicitudes mediante API en AirTable\n",
    "headers = {\"Authorization\" : f\"Bearer {API_KEY}\",\n",
    "           \"Content-Type\"  : \"application/json\"}\n",
    "\n",
    "API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f9f7e-6cee-4777-920d-bf2a490f3c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('kayak_webscraping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d504e-a697-4466-974f-b0101b3c775e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48f80b-2710-4c1d-98cf-e036a09f6fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.replace({\"\" :  None})\n",
    "df = df.replace({np.nan :  None})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668acec-c53b-4cd3-a99f-bbcd71ba6916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datos_df = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    data = {'fields': row.to_dict()}\n",
    "    datos_df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed648943-6460-4284-9e28-5a2e8402cb4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear records en la tabla AirTable\n",
    "\n",
    "# Endpoint\n",
    "endpoint = f\"{airtable_base_url}/{BASE_ID}/{TABLE_ID}\"\n",
    "\n",
    "counter = 0\n",
    "\n",
    "while counter < len(datos_df):\n",
    "    \n",
    "    if counter % 50 == 0:\n",
    "        print(f'Subiendo de {counter} de {len(datos_df)}')\n",
    "        \n",
    "    datos_subir = datos_df[counter:counter+10]\n",
    "    datos_subir = {'records': datos_subir, 'typecast': True }\n",
    "    \n",
    "    response = requests.post(url = endpoint, json = datos_subir, headers = headers)\n",
    "\n",
    "    print(f\"response: {response.status_code}\")\n",
    "    print(f\"endpoint: {response.url}\")\n",
    "    print(\"-\"*120)\n",
    "    counter += 10\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855249d",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c706f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(load_dotenv())\n",
    "\n",
    "API_KEY = os.getenv(\"AIRTABLE_API_KEY\") #API KEY de AirTable cargada desde el ordenador mediante un fichero .env\n",
    "\n",
    "BASE_ID = \"appeoVItHkVNqxCPe\" # Base: Tabla API\n",
    "\n",
    "TABLE_ID = \"tblc9PqQwMxECrPf0\" # Tabla: Data Base\n",
    "\n",
    "airtable_base_url = \"https://api.airtable.com/v0\"\n",
    "\n",
    "# Headers - Credenciales para hacer solicitudes mediante API en AirTable\n",
    "headers = {\"Authorization\" : f\"Bearer {API_KEY}\",\n",
    "           \"Content-Type\"  : \"application/json\"}\n",
    "\n",
    "API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e8824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Descargar los datos de AirTable\n",
    "\n",
    "endpoint = f\"{airtable_base_url}/{BASE_ID}/{TABLE_ID}\"\n",
    "\n",
    "params = {}\n",
    "\n",
    "datos = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    response = requests.get(url = endpoint, headers = headers, params = params)\n",
    "    \n",
    "    data = response.json()\n",
    "\n",
    "    datos.extend(data['records'])\n",
    "    \n",
    "    offset = data.get(\"offset\")\n",
    "\n",
    "    if offset is None:\n",
    "        break\n",
    "    \n",
    "    params[\"offset\"] = offset\n",
    "    \n",
    "    # sleep(1)\n",
    "    print(f'Descargados {len(datos)} datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e504ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([x['fields'] for x in datos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937f372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e76a53-817a-4358-a1ea-777ab8dcdf33",
   "metadata": {},
   "source": [
    "## Análisis de datos\n",
    "\n",
    "\n",
    "### 1. Limpieza de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5101c-6fda-4e99-8257-ce5d55f26af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#En caso de querer ejecutar las visualizaciones sin descargar los datos que se encuentran en AirTable, ejecutar esta línea de código (el archivo .pkl estará adjunto en el mail)\n",
    "df = pd.read_pickle('airtable.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36d6ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#En primer lugar añadiré una nueva columna para definir si los datos son de kayak o de edreams\n",
    "\n",
    "def asignar_pagina_web(url):\n",
    "    if \"kayak\" in url.lower():\n",
    "        return \"kayak\"\n",
    "    elif 'edreams' in url.lower():\n",
    "        return \"edreams\"\n",
    "    else:\n",
    "        return \"otro\"\n",
    "\n",
    "# Crear una nueva columna 'pagina_web' usando la función asignar_pagina_web\n",
    "df[\"pagina_web\"] = df[\"url\"].apply(asignar_pagina_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8b608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Luego creamos dos columnas nuevas en las que a partir del iata.pkl transformamos los códigos iata del origen y destino al nombre de la ciudad.\n",
    "def convertir_iata(codigo):\n",
    "    \n",
    "    with open(\"iata.pkl\", \"br\") as file:\n",
    "        ciudades_iata = pickle.load(file)\n",
    "        \n",
    "    for nombre_ciudad, codigo_iata in ciudades_iata.items():\n",
    "        if codigo == codigo_iata:\n",
    "            \n",
    "            return nombre_ciudad\n",
    "\n",
    "df[[\"ciudad_origen\",\"ciudad_destino\"]] = df[[\"origen\",\"destino\"]].apply(lambda codigo: codigo.apply(convertir_iata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755c2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"ciudad_destino\"].value_counts() #comprobamos que el código funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b034c7f-74dc-44ea-9053-7ecfe51e3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = [column for column in df.columns if \"inicio\" in column or \"fin\" in column]\n",
    "df[datetime_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda579c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertir_duracion_a_timedelta(duracion):\n",
    "    partes = duracion.split(' ')\n",
    "    horas = 0\n",
    "    minutos = 0\n",
    "\n",
    "    if \"h\" in partes[0]:\n",
    "        horas = int(partes[0].split('h')[0])\n",
    "\n",
    "    if \"m\" in partes[-1]:\n",
    "        minutos = int(partes[-1].split('m')[0])\n",
    "\n",
    "    return timedelta(hours= horas, minutes= minutos)\n",
    "\n",
    "\n",
    "#Aplicamos la función a las columnas 'duracion_ida' y 'duracion_vuelta' del DataFrame df\n",
    "df[\"duracion_ida\"] = df[\"duracion_ida\"].apply(convertir_duracion_a_timedelta)\n",
    "df[\"duracion_vuelta\"] = df[\"duracion_vuelta\"].apply(convertir_duracion_a_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf36bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime_columns = [column for column in df.columns if \"inicio\" in column or \"fin\" in column]\n",
    "\n",
    "# Limpieza de celdas que contienen \"+\"\n",
    "df[['fin_ida','fin_vuelta']] = df[['fin_ida','fin_vuelta']].apply(lambda hora: hora.str.split('+').str[0])\n",
    "\n",
    "for column in datetime_columns:\n",
    "    \n",
    "    if \"fecha\" not in column:\n",
    "        df[column] = pd.to_datetime(df[column]).apply(lambda x : x.time())\n",
    "        \n",
    "    else:\n",
    "        df[column] = pd.to_datetime(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a3beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "integer_columns = [column for column in df.columns if \"pasajeros\" in column or \"escala\" in column or \"equipaje\" in column]\n",
    "\n",
    "for column in integer_columns:\n",
    "    df[column] = df[column].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d7ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"num_aerolineas\"] = df[\"aerolineas\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f47ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.explode(\"aerolineas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88132b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"aerolineas\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7001aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Finalmente me quedaré sólo con las fechas de navidad para comparar los resultados de ambas páginas web\n",
    "df = df[~df[\"fecha_inicio\"].isin([\"2023-12-06\", \"2024-01-05\"])]\n",
    "#Además, sólo analizaremos los resultados que salgan de Madrid\n",
    "df = df[df['origen'] == 'MAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8707f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes # Así terminamos con un df en el cuál podremos extraer información de los vuelos que nos ofrece cada\n",
    "          # una de las páginas web en función de la fecha de salida, de vuelta, la duración del vuelo, los horarios de salido y vuelta\n",
    "          # así como las condiciones del vuelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8d0ac",
   "metadata": {},
   "source": [
    "### 2. Preguntas sobre los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f847f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059e67e",
   "metadata": {},
   "source": [
    "Observamos la variedad de precios que se obtienen por destino saliendo desde Madrid en las fechas de Navidad y Año Nuevo.\n",
    "Para acotar estos resultados nos haremos ciertas preguntas específicas sobre los datos para poder el elegir el vuelo que más nos convenga para estas vacaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722c343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribución de precios por ciudad de origen y destino\n",
    "fig = px.box(df, x = \"ciudad_origen\", y = \"precio\", color=\"ciudad_destino\",\n",
    "             labels = {\"precio\": \"Precio\", \"ciudad_origen\": \"Ciudad de Origen\", \"ciudad_destino\": \"Ciudad de Destino\"},\n",
    "             title = \"Distribución de precios de vuelos por ciudad de origen y destino\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b4dab",
   "metadata": {},
   "source": [
    "Al analizar los datos hemos observado que entre las aerolíneas también estaban compañías no aéreas, por lo que filtramos el df para quedarnos sólo con las vuelos. Consideramos interesante evaluar la proporción de esos trayectos no aéreos que nos dan las páginas web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc1e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Primero contabilizamos el número de vuelos y de los otros transportes\n",
    "otros_transportes = ['SNCF','Segesta Autolinee', 'iryo','Coastal', 'Renfe','Flibco','BlaBlaBus', 'ALSA','FlixBus',\n",
    "                     'Trenitalia','Autobús','Sagalés','Gipsyy', 'GoOpti', 'Socibus', 'AccessRail', 'Union Ivkoni']\n",
    "\n",
    "num_vuelos = len(df) - df.explode('aerolineas')['aerolineas'].isin(otros_transportes).sum()\n",
    "num_otros_transportes = df.explode('aerolineas')['aerolineas'].isin(otros_transportes).sum()\n",
    "\n",
    "\n",
    "#Creamos una lista y etiquetamos las categorías\n",
    "valores = [num_vuelos, num_otros_transportes]\n",
    "categorias = ['vuelos', 'otros transportes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24040765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Realizamos una visualización del resultado\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(valores, labels=categorias, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Proporción de vuelos y otros transportes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6451761-0387-4cbc-b3e7-2c3fa5873924",
   "metadata": {},
   "source": [
    "Del total de vuelos que nos ofrecen las dos páginas webs, un 2.2% se corresponden a viajes en trenes, buses y afines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae723d-072f-46b3-8f4e-85663b69bd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tras comprobar que no sólo tenemos viajes operados por vuelos, sino también por trenes, autobuses, etc. Deseamos eliminar esas\n",
    "#compañías para sólo tener los vuelos\n",
    "def eliminar_aerolineas(df, lista_aerolineas):\n",
    "    df = df[~df['aerolineas'].isin(lista_aerolineas)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06c0c3-4aa1-4511-b0cc-1fdf1ec44eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "# Llamando a la función y guardando el DataFrame resultante en una nueva variable\n",
    "df = eliminar_aerolineas(df, otros_transportes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad63cf",
   "metadata": {},
   "source": [
    "### Mapeo de las ciudades con el precio medio más barato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f1f7f-3dbb-4e6c-bf76-fe07a1d7cd55",
   "metadata": {},
   "source": [
    "En esta sección se extrae una lista de los top 10 destinos con un precio medio de ticket más económico, además de graficar una lista de hasta 50 posibles sitios/lugares de interés para visitar en cada una de esas ciudades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cd0b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lugares = df.groupby(\"ciudad_destino\")['precio'].mean().sort_values()[:10].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048bef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lugares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1104bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lista_ciudades = df_lugares[\"ciudad_destino\"].unique()\n",
    "\n",
    "data_lugares = []\n",
    "\n",
    "lugares_columns = ['ciudad', 'name', 'fsq_id', 'category', 'latitude', 'longitude', 'country', 'full_location', 'postcode', 'closed_bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7f803-527d-47b4-918a-68cdfa3ac2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credenciales API KEY para API de FOURSQUARE\n",
    "\n",
    "print(load_dotenv())\n",
    "\n",
    "API_KEY = os.getenv('FOURSQUARE_API_KEY')\n",
    "\n",
    "API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c6af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ciudad in lista_ciudades:\n",
    "\n",
    "    # Base del Endpoint\n",
    "    search_url = \"https://api.foursquare.com/v3/places/search\"\n",
    "\n",
    "    url_params = {\"categories\"    : \"16000\",#Este id de categoría corresponde a Landmarks and Outdoors, para sacar posibles sitios de interés qué visitar\n",
    "                  \"near\"       : ciudad,\n",
    "                  \"limit\"    : 50}\n",
    "\n",
    "    headers = {\"accept\"       : \"application/json\", \n",
    "               \"Authorization\": API_KEY}\n",
    "    try:\n",
    "        # Como ahora usamos una variable para los parámetros, debemos agregarlos con el parámetro \"params\"\n",
    "        response = requests.get(url = search_url, params = url_params, headers = headers)\n",
    "\n",
    "        print(f\"response: {response.status_code}\")\n",
    "        print(f\"endpoint: {response.url}\")\n",
    "\n",
    "        lugares = response.json()['results']\n",
    "\n",
    "        sleep(2)\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        for lugar in lugares:\n",
    "\n",
    "            category = lugar['categories'][0]['name'] if len(lugar['categories']) else None\n",
    "            fsq_id = lugar['fsq_id']\n",
    "            latitude = lugar['geocodes']['main']['latitude']\n",
    "            longitude = lugar['geocodes']['main']['longitude']\n",
    "            full_location = lugar['location']['formatted_address']\n",
    "            country = lugar['location']['country']\n",
    "            postcode = lugar['location'].get('postcode')\n",
    "            closed_bucket = lugar['closed_bucket']\n",
    "            name = lugar['name']\n",
    "\n",
    "            data_lugares.append([ciudad, name, fsq_id, category, latitude, longitude, country, full_location, postcode, closed_bucket])\n",
    "            counter += 1\n",
    "\n",
    "        print(f'Extraídos {counter} lugares de {ciudad}')\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31246802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lugares = pd.DataFrame(data_lugares, columns = lugares_columns)\n",
    "df_lugares.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec9494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centro = (df_lugares['latitude'].mean(), df_lugares['longitude'].mean())\n",
    "\n",
    "mapa = folium.Map(location = centro, zoom_start = 5)\n",
    "\n",
    "sitios = folium.map.FeatureGroup()\n",
    "\n",
    "for idx, row in df_lugares.iterrows():\n",
    "\n",
    "    lat = row[\"latitude\"]\n",
    "    lng = row[\"longitude\"]\n",
    "    label = row[\"name\"]\n",
    "    category = row[\"category\"]\n",
    "    \n",
    "    sitios.add_child(folium.Marker(location = [lat, lng],\n",
    "                                    popup    = f\"{label}, {category}\"))\n",
    "    \n",
    "mapa.add_child(sitios)\n",
    "\n",
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96957435",
   "metadata": {},
   "source": [
    "#### ¿Cuántos destinos obtengo en cada página web en cada una de las fechas establecidas? ¿Cuántos vuelos por destino obtengo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756dac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Para contestar a estas preguntas realizaremos una agrupación por fecha de inicio de cada vuelo y el destino.\n",
    "#Así obtendremos el número de destinos únicos por cada vuelo. Así como el número de vuelos por cada destino.\n",
    "\n",
    "destinos_por_fecha = df.groupby([\"pagina_web\", \"fecha_inicio\"])[\"destino\"].nunique().reset_index()\n",
    "vuelos_por_destino = df.groupby([\"pagina_web\", \"ciudad_destino\"]).size().reset_index(name = \"num_vuelos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c3970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_por_fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f759d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos_por_destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355cbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ordenamos las ciudades alfabéticamente\n",
    "vuelos_por_destino_sorted = vuelos_por_destino.sort_values(by=\"ciudad_destino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58c031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Representamos estos cálculos mediante un gráfico de barras para destinos por fecha y página web\n",
    "fig_destinos = px.bar(destinos_por_fecha, x = \"fecha_inicio\", y = \"destino\", color = \"pagina_web\",\n",
    "                      title = \"Número de destinos por fecha\",\n",
    "                      labels = {\"destino\": \"Número de destinos únicos\"},\n",
    "                      category_orders = {\"pagina_web\": [\"kayak\", \"edreams\"]})\n",
    "fig_destinos.show()\n",
    "\n",
    "#Y otro para vuelos por destino\n",
    "fig_vuelos = px.bar(vuelos_por_destino, x = \"ciudad_destino\", y = \"num_vuelos\", color = \"pagina_web\",\n",
    "                    title = \"Número de vuelos por destino\",\n",
    "                    labels = {\"num_vuelos\": \"Número de vuelos\"},\n",
    "                    category_orders = {\"pagina_web\": [\"kayak\", \"edreams\"]})\n",
    "fig_vuelos.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa960d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Luego ya concatenamos los resultados y especificamos keys como: kayak y edreams.\n",
    "#Así podriamos generar tablas para que se pueden extraer o analizarlas.\n",
    "resumen_destinos = pd.concat([destinos_por_fecha[destinos_por_fecha['pagina_web'] == 'kayak'], \n",
    "                              destinos_por_fecha[destinos_por_fecha['pagina_web'] == 'edreams']], \n",
    "                             keys=[\"kayak\", \"edreams\"])\n",
    "\n",
    "resumen_vuelos = pd.concat([vuelos_por_destino[vuelos_por_destino['pagina_web'] == 'kayak'], \n",
    "                            vuelos_por_destino[vuelos_por_destino['pagina_web'] == 'edreams']], \n",
    "                           keys=[\"kayak\", \"edreams\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95b26a",
   "metadata": {},
   "source": [
    "En la gráfica en la que observamos el número de destinos por fecha, vemos que hemos obtenido una gran contidad de datos de datos de kayak en comparación a edreams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97f4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"pagina_web\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e516dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resumen_destinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d062a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resumen_vuelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac13cf",
   "metadata": {},
   "source": [
    "Si nos interesa ver las aerolíneas que operan para cada destino, podríamos extraer información del resumen vuelo.\n",
    "Además, aquí representamos el número de aerolíneas que operan en los vuelos que nos ofrece cada página web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d395a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Con un boxplot podríamos visualizar si existen diferencias entre el número de aerolíneas que operan en los vuelos de los destinos\n",
    "#que nos ofrece cada página web.\n",
    "\n",
    "fig = px.box(resumen_vuelos, x = \"pagina_web\", y = \"num_vuelos\", color = \"pagina_web\",\n",
    "             category_orders = {\"pagina_web\": [\"kayak\", \"edreams\"]})\n",
    "\n",
    "# Actualizar las etiquetas del eje x y el título\n",
    "fig.update_xaxes(tickvals = [0, 1], ticktext = [\"Kayak\", \"eDreams\"], title_text = \"Página Web\")\n",
    "fig.update_yaxes(title_text = \"Número de aerolíneas\")\n",
    "fig.update_layout(title_text = \"Número de aerolíneas por destino\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1fa93",
   "metadata": {},
   "source": [
    "### De todos estos vuelos: ¿cuál es el porcentaje de vuelos que opera con más de una aerolínea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5733d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Para poder responder a esta pregunta se define la siguiente función en la que primero determinamos\n",
    "#es los vuelos que tengan más de una aerolinea. Luego calculamos el porcentaje.\n",
    "#Finalmente lo apliamos a los destinos filtrados pero en función de lo que nos ofrezca kayak o edreams.\n",
    "#\n",
    "\n",
    "def calcular_porcentaje_vuelos_mas_de_una_aerolinea(df, pagina_web):\n",
    "    \n",
    "    vuelos_mas_de_una_aerolinea = df[(df[\"num_aerolineas\"] > 1) & (df[\"pagina_web\"] == pagina_web)]\n",
    "    porcentaje_vuelos_mas_de_una_aerolinea = (len(vuelos_mas_de_una_aerolinea) / len(df[df[\"pagina_web\"] == pagina_web])) * 100\n",
    "    \n",
    "    return porcentaje_vuelos_mas_de_una_aerolinea\n",
    "\n",
    "porcentaje_kayak = calcular_porcentaje_vuelos_mas_de_una_aerolinea(df, \"kayak\")\n",
    "porcentaje_edreams = calcular_porcentaje_vuelos_mas_de_una_aerolinea(df, \"edreams\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7d7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convertimos los datos en DataFrame para poder representarlos en un gráfico de pastel.\n",
    "data = {\"Porcentaje\": [porcentaje_kayak, porcentaje_edreams],\n",
    "        \"Pagina Web\": [\"Kayak\", \"eDreams\"]}\n",
    "\n",
    "df_porcentajes = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "fig = px.pie(df_porcentajes, names = \"Pagina Web\", values = \"Porcentaje\", title = \"Porcentaje de vuelos con más de una aerolínea\",\n",
    "             labels = {\"Porcentaje\": \"Porcentaje de Vuelos (%)\"},\n",
    "             color_discrete_sequence = px.colors.qualitative.Set1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397733a5",
   "metadata": {},
   "source": [
    "A lo mejor nos interesa que el vuelo sea gestionado por una sola aerolínea en caso de que haya retrasos o se deba pedir indemnizaciones. O bien, nos gusta el servicio de una aerolínea en concreto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3063b03",
   "metadata": {},
   "source": [
    "### De los distintos destinos que me ofrecen en kayak y eDreams: ¿cuál de ellos me ofrecen destinos más baratos? entre un rango de 100-250 euros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda24d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Primero vamos a filtrar por el rango de precio que hemos definido.\n",
    "def filtrar_destinos_por_precio(df, precio_min, precio_max):\n",
    "    destinos_filtrados = df[(df[\"precio\"] >= precio_min) & (df[\"precio\"] <= precio_max)]\n",
    "    \n",
    "    return destinos_filtrados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38320390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_filtrados = filtrar_destinos_por_precio(df, 100, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5e16d-209b-4ebf-8317-a10265b3b833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_filtrados['aerolineas'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126b5e8-ffb4-440f-8928-2f5605fe19cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_filtrados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd3e1a",
   "metadata": {},
   "source": [
    "Si volvemos a agrupar el destino por fecha y los vuelos por destino una vez hemos definido un df con destinos filtrados en el rango de precio de 100-250€ vemos que el número de destino por cada fecha ha disminuído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07c412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_por_fecha = destinos_filtrados.groupby([\"pagina_web\", \"fecha_inicio\"])[\"destino\"].nunique().reset_index()\n",
    "vuelos_por_destino = destinos_filtrados.groupby([\"pagina_web\", \"fecha_inicio\", \"ciudad_destino\"]).size().reset_index(name = \"num_vuelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c4e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ordenamos las ciudades alfabéticamente\n",
    "vuelos_por_destino_sorted = vuelos_por_destino.sort_values(by=\"ciudad_destino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e3b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Representamos estos cálculos mediante un gráfico de barras para destinos por fecha y página web\n",
    "fig_destinos = px.bar(destinos_por_fecha, x = \"fecha_inicio\", y = \"destino\", color = \"pagina_web\",\n",
    "                      title = \"Número de destinos por fecha\",\n",
    "                      labels = {\"destino\": \"Número de destinos únicos\"},\n",
    "                      category_orders = {\"pagina_web\": [\"kayak\", \"edreams\"]})\n",
    "fig_destinos.show()\n",
    "\n",
    "#Y otro para vuelos por destino\n",
    "fig_vuelos = px.bar(vuelos_por_destino, x = \"ciudad_destino\", y = \"num_vuelos\", color = \"pagina_web\",\n",
    "                    title = \"Número de vuelos por pestino\",\n",
    "                    labels = {\"num_vuelos\": \"Número de vuelos\"},\n",
    "                    category_orders = {\"pagina_web\": [\"kayak\", \"edreams\"]})\n",
    "fig_vuelos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01124d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Primero debemos calcular la duración total del vuelo (ida y vuelta)\n",
    "destinos_filtrados[\"duracion_total\"] = destinos_filtrados[\"duracion_ida\"] + destinos_filtrados[\"duracion_vuelta\"]\n",
    "\n",
    "\n",
    "# Antes filtraremos\n",
    "Q1, Q3 = np.percentile(destinos_filtrados['duracion_total'], [25, 75])\n",
    "IQR = Q3 - Q1\n",
    "techo = Q3 + 1.5 * IQR\n",
    "piso = Q1 - 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a8719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_filtrados_2 = destinos_filtrados[destinos_filtrados['duracion_total'].between(piso, techo)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89363cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.box(destinos_filtrados_2, x = \"pagina_web\", y = \"duracion_total\", color = \"pagina_web\",\n",
    "             category_orders = {\"pagina_web\": [\"kayak\", \"edreams\"]})\n",
    "\n",
    "fig.update_xaxes(tickvals = [0, 1], ticktext = [\"Kayak\", \"eDreams\"], title_text = \"Página Web\")\n",
    "fig.update_yaxes(title_text = \"Duración total (minutos)\")\n",
    "fig.update_layout(title_text = \"Distribución de la duración total de vuelos (Ida-Vuelta)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9a8ba",
   "metadata": {},
   "source": [
    "### Evaluaremos los horarios de ida y vuelta que nos ofrece kayak y edreams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac0ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categorizaría las horas de salida y de vuelta para analizar de esos precios: \n",
    "#¿cuáles salen a primera hora de la mañana? Ya que nos gustaría aprovechar lo máximo. Lo ideal sería que salga a primera hora de la mañana, no?\n",
    "#de los vuelos de vuelta, ¿cuáles salen a última hora? Nos gustaría volver a última hora para aprovechar el último día o por la tarde,\n",
    "#así podemos llegar con calma, deshacer la maleta y descansa antes de volver a la rutina?\n",
    "\n",
    "# Función para categorizar los horarios en 'Mañana' o 'Tarde'\n",
    "def categorizar_horario(hora):\n",
    "    if hora >= pd.to_datetime('5:00:00', format='%H:%M:%S').time() and hora <= pd.to_datetime('14:00:00', format='%H:%M:%S').time():\n",
    "        return 'Mañana'\n",
    "    elif hora >= pd.to_datetime('14:00:01', format='%H:%M:%S').time() and hora <= pd.to_datetime('23:59:59', format='%H:%M:%S').time():\n",
    "        return 'Tarde'\n",
    "    elif hora >= pd.to_datetime('00:00:00', format='%H:%M:%S').time() and hora <= pd.to_datetime('04:59:59', format='%H:%M:%S').time():\n",
    "        return 'Tarde'\n",
    "    else:\n",
    "        return 'Otro'\n",
    "\n",
    "#Aplicamos la función de categorización a las columnas de inicio y fin (ida y vuelta)\n",
    "df[['categoria_inicio_ida', 'categoria_inicio_vuelta']] = df[['inicio_ida', 'inicio_vuelta']].applymap(lambda x: categorizar_horario(x))\n",
    "\n",
    "# También lo aplicaré al df de destinos_filtrados\n",
    "destinos_filtrados['categoria_inicio_ida'] = destinos_filtrados['inicio_ida'].apply(categorizar_horario)\n",
    "destinos_filtrados['categoria_inicio_vuelta'] = destinos_filtrados['fin_vuelta'].apply(categorizar_horario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59845705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e8ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "destinos_filtrados.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62063ff4-7304-4994-98b6-b66fd463b4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tras la categorización quiero saber qué página web me ofrece vuelos de inicio_ida de Mañana y vuelos de inicio_vuelta de Tarde\n",
    "#Para eso agrupo mis datos filtrados por página web, la categoría de horas y contamos el número de vuelos.\n",
    "\n",
    "vuelos_manana_ida = destinos_filtrados[destinos_filtrados[\"categoria_inicio_ida\"] == \"Mañana\"].groupby(\"pagina_web\")[\"ciudad_destino\"].unique()\n",
    "vuelos_tarde_vuelta = destinos_filtrados[destinos_filtrados[\"categoria_inicio_vuelta\"] == \"Tarde\"].groupby(\"pagina_web\")[\"ciudad_destino\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751cd260-9066-4329-9c39-ba9a8bada207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(vuelos_manana_ida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4a1a3",
   "metadata": {},
   "source": [
    "Observamos que el número de vuelos que me ofrecen salir por la mañana y volver por la tarde es similar para cada página web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca0ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Primero creamos un df para los resultados\n",
    "data = {\n",
    "    'pagina_web': ['kayak', 'edreams'],\n",
    "    'vuelos_manana_ida': [len(vuelos_manana_ida['kayak']), len(vuelos_manana_ida['edreams'])],\n",
    "    'vuelos_tarde_vuelta': [len(vuelos_tarde_vuelta['kayak']), len(vuelos_tarde_vuelta['edreams'])]\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame(data)\n",
    "\n",
    "# Generamos el gráfico de barras apiladas para visualizar la cantidad de vuelos que me ofrecen una ida de mañana y vuelta de tarde\n",
    "fig = px.bar(df_resultados, x = \"pagina_web\", y = [\"vuelos_manana_ida\", \"vuelos_tarde_vuelta\"],\n",
    "             title = \"Número de destinos únicos por categoría horaria\",\n",
    "             labels = {\"value\": \"Número de destinos únicos\"},\n",
    "             color_discrete_sequence=[\"lightblue\", \"orange\"])\n",
    "\n",
    "fig.update_layout(barmode=\"stack\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2609c4",
   "metadata": {},
   "source": [
    "### Evaluaremos las condiciones de escalas, equipaje, las aerolíneas que operan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d292f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analizar_condiciones_companias(df, pagina_web):\n",
    "    df_pagina_web = df[df[\"pagina_web\"] == pagina_web]\n",
    "    \n",
    "    resultados = {}\n",
    "    \n",
    "    # Equipaje de mano permitido\n",
    "    vuelos_con_equipaje_mano = df_pagina_web[df_pagina_web[\"equipaje_mano\"] > 0].shape[0]\n",
    "    resultados[\"vuelos_con_equipaje_mano\"] = vuelos_con_equipaje_mano\n",
    "    \n",
    "    # Equipaje de bodega permitido\n",
    "    vuelos_con_equipaje_bodega = df_pagina_web[df_pagina_web[\"equipaje_bodega\"] > 0].shape[0]\n",
    "    resultados[\"vuelos_con_equipaje_bodega\"] = vuelos_con_equipaje_bodega\n",
    "    \n",
    "    # Número de aerolíneas únicas que operan\n",
    "    aerolineas_unicas = df_pagina_web[\"aerolineas\"].explode().unique()\n",
    "    cantidad_aerolineas_unicas = len(aerolineas_unicas)\n",
    "    resultados[\"cantidad_aerolineas_unicas\"] = cantidad_aerolineas_unicas\n",
    "    \n",
    "    # Número de escalas en los vuelos de ida\n",
    "    numero_escalas_ida = df_pagina_web[\"escala_ida\"].apply(lambda x: len(x) if isinstance(x, (list, str)) else 0).sum()\n",
    "    resultados[\"numero_escalas_ida\"] = numero_escalas_ida\n",
    "    \n",
    "    # Número de escalas en los vuelos de vuelta\n",
    "    numero_escalas_vuelta = df_pagina_web[\"escala_vuelta\"].apply(lambda x: len(x) if isinstance(x, (list, str)) else 0).sum()\n",
    "    resultados[\"numero_escalas_vuelta\"] = numero_escalas_vuelta\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "#Aplicamos la función al df de destinos_filtrados y la página web específica\n",
    "resultados_condiciones_kayak = analizar_condiciones_companias(destinos_filtrados, \"kayak\")\n",
    "resultados_condiciones_edreams = analizar_condiciones_companias(destinos_filtrados, \"edreams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119089f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resultados_condiciones_kayak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730aaf6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resultados_condiciones_edreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff9144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creamos un DataFrame con los resultados específicos para cada página web\n",
    "resultados_df = pd.DataFrame({\n",
    "    \"Categorias\": [\"Vuelos con equipaje de mano\", \"Vuelos con equipaje de bodega\",\n",
    "                  \"Cantidad de aerolíneas únicas\"],\n",
    "    \"Kayak\": [\n",
    "        resultados_condiciones_kayak[\"vuelos_con_equipaje_mano\"],\n",
    "        resultados_condiciones_kayak[\"vuelos_con_equipaje_bodega\"],\n",
    "        resultados_condiciones_kayak[\"cantidad_aerolineas_unicas\"]\n",
    "    ],\n",
    "    \"eDreams\": [\n",
    "        resultados_condiciones_edreams[\"vuelos_con_equipaje_mano\"],\n",
    "        resultados_condiciones_edreams[\"vuelos_con_equipaje_bodega\"],\n",
    "        resultados_condiciones_edreams[\"cantidad_aerolineas_unicas\"]\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b271ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(resultados_df, x = \"Categorias\", y = [\"Kayak\", \"eDreams\"],\n",
    "                 title = \"Comparación de condiciones de vuelo: Kayak vs eDreams\",\n",
    "                 labels = {\"value\": \"Cantidad\"},\n",
    "                 color_discrete_sequence = [\"blue\", \"orange\"])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165140f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtener la lista de aerolíneas únicas que operan en los vuelos\n",
    "aerolineas_unicas = destinos_filtrados['aerolineas'].explode().unique()\n",
    "print(f'Aerolíneas que operan en los vuelos: {aerolineas_unicas}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
